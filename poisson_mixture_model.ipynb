{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from typing import *\n",
    "\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各分布のハイパーパラメーターを保持するクラスを作る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of * distribution\n",
    "class Gamma:\n",
    "    def __init__(self, *, a: List[float], b: float):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        \n",
    "    def get():\n",
    "        \"\"\" ガンマ分布をscipyのfrozen RV objectの形で返す。\n",
    "        Notes:\n",
    "            scipyのgamma distは、教科書の定義とちょっと異なる。教科書で言うハイパーパラメーターbは、scaleという名前で指定する。\n",
    "            https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gamma.html\n",
    "        \"\"\"\n",
    "        return [stats.gamma(a=elem, scale=b) for elem in self.a]\n",
    "\n",
    "\n",
    "class Poisson:\n",
    "    def __init__(self, *, lambda_: List[float]):\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    def get():\n",
    "        \"\"\" ポアソン分布をscipyのfrozen RV objectの形で返す。\"\"\"\n",
    "        return [stats.poisson(mu=elem) for elem in self.lambda_]\n",
    "\n",
    "\n",
    "class BayesPoiMixModel:\n",
    "    def __init__(self, *, num_dim: int, num_cluster: int, alpha: List[float], gamDists: List[Gamma]):\n",
    "        \"\"\" ポアソン混合モデルの事前・事後分布を表現するクラスを構築する。\n",
    "        Args:\n",
    "            D: 観測データの次元\n",
    "            K: クラスター数\n",
    "            alpha : カテゴリ分布のパラメーター $\\pi$ の共役事前分布であるディリクレ分布のハイパーパラメーター (p.119)\n",
    "            gamLists: ポアソン分布のパラメーター $\\lambda$ の共役事前分布であるガンマ分布のハイパーパラメーター (p.129)\n",
    "        \"\"\"\n",
    "        self.num_dim = num_dim\n",
    "        self.num_cluster = num_cluster\n",
    "        self.alpha = alpha\n",
    "        self.gamDists = gamDists\n",
    "\n",
    "\n",
    "class PoiMixModel:\n",
    "    def __init__(self, *, num_dim: int, num_cluster: int, alpha: List[float], poiDists: List[Poisson]):\n",
    "        \"\"\" 真のポアソン混合モデルを構築する。\n",
    "        Args:\n",
    "            D: 観測データの次元\n",
    "            K: クラスター数\n",
    "            alpha : \n",
    "            poiDists: \n",
    "        \"\"\"\n",
    "        self.num_dim = num_dim\n",
    "        self.num_cluster = num_cluster\n",
    "        self.phi = alpha\n",
    "        self.poiDists = poiDists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ユーティリティ関数を定義する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ELBO(X, prior: BayesPoiMixModel, posterior: BayesPoiMixModel): # X: Mat{float}\n",
    "    \"\"\" ELBOを計算する。付録A.4を参照のこと。\n",
    "    Args:\n",
    "        X: \n",
    "        prior: \n",
    "        posterior: \n",
    "    \"\"\"\n",
    "    ln_expt_S = update_S(pos, X)\n",
    "    expt_S = np.exp(ln_expt_S)\n",
    "    K, N = expt_S.shape\n",
    "    D = X.shape[0]\n",
    "\n",
    "    expt_ln_lambda = np.zeros(S.shape) #np.matrix(np.zeros(D, K))\n",
    "    expt_lambda = np.zeros(S.shape) #np.matrix(np.zeros(D, K))\n",
    "    expt_ln_lkh = 0\n",
    "    for k in range(K):\n",
    "        expt_ln_lambda[:,k] = np.digamma(pos.cmp[k].a) - np.log(pos.cmp[k].b)\n",
    "        expt_lambda[:,k] = pos.cmp[k].a / pos.cmp[k].b\n",
    "        for n in range(N)\n",
    "            expt_ln_lkh += expt_S[k,n] * (\n",
    "                X[:, n].T * expt_ln_lambda[:,k] \n",
    "                    - sum(expt_lambda[:,k]) - sum(np.lgamma(X[:,n]+1))\n",
    "            )[1]\n",
    "\n",
    "    expt_ln_pS = sum(expt_S.T * (np.digamma(pos.alpha) - np.digamma(sum(pos.alpha))))\n",
    "    expt_ln_qS = sum(expt_S .* ln_expt_S)\n",
    "    KL_lambda = 0\n",
    "    for k in range(K):\n",
    "        KL_lambda += (\n",
    "            sum(pos.cmp[k].a)*np.log(pos.cmp[k].b) - sum(pri.cmp[k].a)*np.log(pri.cmp[k].b)\n",
    "                - sum(np.lgamma(pos.cmp[k].a)) + sum(np.lgamma(pri.cmp[k].a))\n",
    "                + (pos.cmp[k].a - pri.cmp[k].a).T * expt_ln_lambda[:,k]\n",
    "                + (pri.cmp[k].b - pos.cmp[k].b) * sum(expt_lambda[:,k])\n",
    "        )[1]\n",
    "    \n",
    "    KL_pi = (\n",
    "        np.lgamma(sum(pos.alpha)) - np.lgamma(sum(pri.alpha))\n",
    "             - sum(np.lgamma(pos.alpha)) + sum(np.lgamma(pri.alpha))\n",
    "             + (pos.alpha - pri.alpha).T * (np.digamma(pos.alpha) - np.digamma(sum(pos.alpha)))\n",
    "    )[1]\n",
    "    return expt_ln_lkh + expt_ln_pS - expt_ln_qS - (KL_lambda + KL_pi)\n",
    "\n",
    "\n",
    "def add_stats(bpmm: BayesPoiMixModel, X, S):  # X: Matrix{Float64}, S: Matrix{Float64}\n",
    "    D = bpmm.D\n",
    "    K = bpmm.K\n",
    "    sum_S = sum(S, 2)\n",
    "    alpha = [bpmm.alpha[k] + sum_S[k] for k in range(K)]\n",
    "    gamDists = [] # Vector{Gam}()\n",
    "    XS = X*(S.T);\n",
    "    for k in range(K):\n",
    "        a = [float(bpmm.cmp[k].a[d] + XS[d,k]) for d range(D)]\n",
    "        b = bpmm.cmp[k].b + sum_S[k]\n",
    "        gamDists.append(Gamma(a=a, b=b))\n",
    "    return BayesPoiMixModel(D=D, K=K, alpha=alpha, gamDists)\n",
    "\n",
    "\n",
    "def remove_stats(bpmm: BayesPoiMixModel, X, S): # X: Matrix{Float64}, S: Matrix{Float64}\n",
    "    return add_stats(bpmm, X, -S)\n",
    "\n",
    "\n",
    "# Pick single states having a max probability.\n",
    "def winner_takes_all(S): # S: Matrix{Float64}\n",
    "    S_ret = np.zeros(S.shape) #  np.matrix(np.zeros(size(S)))\n",
    "    for n in range(S_ret.shape[1])\n",
    "        idx = np.argmax(S[:,n])\n",
    "        S_ret[idx,n] = 1\n",
    "    return S_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a PMM given hyperparameters.\n",
    "def sample_PMM(bpmm: BayesPoiMixModel) -> PoiMixModel:\n",
    "    pois: List[Poisson] = [] \n",
    "    for c in bpmm.gamma_dists:\n",
    "        lambda_: List[float] = []\n",
    "        for d in range(bpmm.D):\n",
    "            lambda_.append(rand(Gamma(c.a[d], 1.0/c.b)))\n",
    "        pois.append(Poisson(lambda_ = lambda_)) \n",
    "    return PoiMixModel(\n",
    "        D = bpmm.D \n",
    "        , K = bpmm.K \n",
    "        , phi = rand(Dirichlet(bpmm.alpha))\n",
    "        , pois\n",
    "    )\n",
    "\n",
    "# Sample data from a specific PMM model.\n",
    "def sample_data(pmm: PoiMixModel, N: int):\n",
    "    X = np.zeros(pmm.D, N) #np.matrix(np.zeros(pmm.D, N))\n",
    "    S = categorical_sample(pmm.phi, N)\n",
    "    for n in range(N):\n",
    "        k = np.argmax(S[:, n])\n",
    "        for d in range(1, pmm.D)\n",
    "            X[d,n] = rand(Poisson(pmm.cmp[k].lambda_[d]))\n",
    "    return X, S\n",
    "\n",
    "#categorical_sample(p::Vector{Float64}) = categorical_sample(p, 1)[:,1]\n",
    "\n",
    "def categorical_sample(p: List[float], N: int = 1):\n",
    "    K = length(p)\n",
    "    S = np.zeros(K, N) # np.matrix(np.zeros(K, N))\n",
    "    S_tmp = rand(Categorical(p), N)\n",
    "    for k in range(K):\n",
    "        S[k,find(S_tmp.==k)] = 1\n",
    "    return S if N != 1 else S[:, 1]\n",
    "\n",
    "\n",
    "def init_S(X, bpmm: BayesPoiMixModel): # X: Matrix{float}\n",
    "    N = X.shape()[1]\n",
    "    S = categorical_sample(np.ones(K)/bpmm.cluster, N)    \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for Gibbs Sampling\n",
    "def sample_S_GS(pmm: PoiMixModel, X):  # X: Matrix{Float64}\n",
    "    D, N = X.shape\n",
    "    K = pmm.K\n",
    "    S = zeros(K, N)\n",
    "\n",
    "    tmp = [-sum(pmm.cmp[k].lambda) + log.(pmm.phi[k]) for k in range(K)]\n",
    "    ln_lambda_X = [X.T*np.log(pmm.cmp[k].lambda) for k in range(K)]\n",
    "    for n in 1 : N\n",
    "        tmp_ln_phi = [(tmp[k] + ln_lambda_X[k][n])::Float64 for k in range(K)]\n",
    "        tmp_ln_phi = tmp_ln_phi - logsumexp(tmp_ln_phi)\n",
    "        S[:,n] = categorical_sample(exp.(tmp_ln_phi))\n",
    "    return S\n",
    "\n",
    "\n",
    "# used for Collapsed Gibbs Sampling\n",
    "def calc_ln_NB(Xn, gam: Gamma): # Xn: Vector{Float64}\n",
    "    return sum([\n",
    "        float(gam.a[d]*np.log(gam.b)\n",
    "            - np.lgamma(gam.a[d])\n",
    "            + np.lgamma(Xn[d] + gam.a[d])\n",
    "            - (Xn[d] + gam.a[d])*np.log(gam.b + 1)\n",
    "        ) for d in range(Xn.shape[0])\n",
    "    ])\n",
    "\n",
    "\n",
    "def sample_Sn(Xn, bpmm: BayesPoiMixModel): # Xn: Vector{Float64}\n",
    "    ln_tmp = [(calc_ln_NB(Xn, bpmm.cmp[k]) + np.log(bpmm.alpha[k])) for k in range(bpmm.K)]\n",
    "    ln_tmp = ln_tmp -  logsumexp(ln_tmp)\n",
    "    Sn = categorical_sample(np.exp(ln_tmp))\n",
    "    return Sn\n",
    "\n",
    "\n",
    "def sample_S_CGS(S, M, bpmm: BayesPoiMixModel):  # S: Matrix{Float64}, X: Matrix{Float64}\n",
    "    D, N = X.shape\n",
    "    K = S.shape[0]\n",
    "    for n in randperm(N)\n",
    "        bpmm = remove_stats(bpmm, X[:,[n]], S[:,[n]])  # remove\n",
    "        S[:,n] = sample_Sn(X[:,n], bpmm)  # sample\n",
    "        bpmm = add_stats(bpmm, X[:,[n]], S[:,[n]])  # insert\n",
    "    return S, bpmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm main\n",
    "\n",
    "# Compute posterior distribution via variational inference.\n",
    "def learn_VI(x, prior_bpmm: BayesPoiMixModel, max_iter: int):  # X: Matrix{Float64}\n",
    "    # initialisation\n",
    "    expt_S = init_S(X, prior_bpmm)\n",
    "    bpmm = add_stats(prior_bpmm, X, expt_S)\n",
    "    history = np.zeros(max_iter)\n",
    "\n",
    "    # inference\n",
    "    for i in range(max_iter)\n",
    "        # E-step\n",
    "        expt_S = np.exp(update_S(bpmm, X))\n",
    "        # M-step\n",
    "        bpmm = add_stats(prior_bpmm, X, expt_S)\n",
    "        # calc VB\n",
    "        history[i] = calc_ELBO(X, prior_bpmm, bpmm)\n",
    "\n",
    "    return expt_S, bpmm, history\n",
    "\n",
    "\n",
    "# Compute posterior distribution via Gibbs sampling.\n",
    "def learn_GS(x, prior_bpmm: BayesPoiMixModel, max_iter: int=1000):  # X::Matrix{Float64}\n",
    "    # initialisation\n",
    "    S = init_S(X, prior_bpmm)\n",
    "    bpmm = add_stats(prior_bpmm, X, S)\n",
    "    history = np.zeros(max_iter)  # * NaN # なぜ？\n",
    "    \n",
    "    # inference\n",
    "    for i in range(max_iter):\n",
    "        # sample parameters\n",
    "        pmm = sample_PMM(bpmm)\n",
    "        # sample latent variables\n",
    "        S = sample_S_GS(pmm, X)\n",
    "        # update current model\n",
    "        bpmm = add_stats(prior_bpmm, X, S)\n",
    "        # calc VB\n",
    "        history[i] = calc_ELBO(X, prior_bpmm, bpmm)\n",
    "\n",
    "    return S, bpmm, history\n",
    "\n",
    "\n",
    "# Compute posterior distribution via collapsed Gibbs sampling.\n",
    "def learn_CGS(x, prior_bpmm: BayesPoiMixModel, max_iter: int=1000):  # X::Matrix{Float64}\n",
    "    # initialisation\n",
    "    S = init_S(X, prior_bpmm)\n",
    "    bpmm = add_stats(prior_bpmm, X, S)\n",
    "    VB = np.zeros(max_iter)  # * NaN # なぜ？\n",
    "    # inference\n",
    "    for i in range(max_iter):\n",
    "        # directly sample S\n",
    "        S, bpmm = sample_S_CGS(S, X, bpmm)\n",
    "        # calc VB\n",
    "        history[i] = calc_ELBO(X, prior_bpmm, bpmm)\n",
    "    return S, bpmm, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hist(ax, X, S, label):\n",
    "    counts, bins, patches = ax.hist(X.T, 20)\n",
    "    for i in range(len(patches)):\n",
    "        if counts[i] > 0:\n",
    "            S_tmp = S[:,bins[i] .<= X[1,:] .<= bins[i+1]]\n",
    "            S_sum = sum(S_tmp, 2) / sum(S_tmp)\n",
    "            patches[i].set_facecolor((S_sum[1], 0, S_sum[2]))\n",
    "    ax.set_title(label)\n",
    "\n",
    "\n",
    "# Visualize data & estimation using 1D histogram.\n",
    "# X::Matrix{Float64}, S::Matrix{Float64}, S_est::Matrix{Float64}\n",
    "def visualize(X, S, S_est):\n",
    "    # separated figures\n",
    "    fig = plt.figure(figsize=(12, 7))\n",
    "    ax1 = fig.add_subplots(1,1,1)#=\"observation\")\n",
    "    ax2 = fig.add_subplots(1,1,2)#num=\"estimation\")\n",
    "    #f1[:clf]()\n",
    "    f#2[:clf]()\n",
    "    #_, ax1 = subplots(1,1,num=\"observation\")\n",
    "    #_, ax2 = subplots(1,1,num=\"estimation\")\n",
    "    ax1.hist(X.T, 20)\n",
    "    ax1.set_title(\"observation\")\n",
    "    draw_hist(ax2, X, S_est, \"estimation\")    \n",
    "\n",
    "# Run a test script for 1D data clustering.\n",
    "def run():\n",
    "    ## set model\n",
    "    num_dim = 1  # data dimension, must be 1.\n",
    "    num_cluster = 2  #  number of mixture components, must be 2.\n",
    "    alpha = 100.0 * np.ones(K)\n",
    "    bpmm = BayesPoiMixModel(\n",
    "        num_dim=num_dim, \n",
    "        num_cluster=num_cluster, \n",
    "        alpha=alpha, \n",
    "        gamLists=[Gamma(a=1.0*np.ones(num_dim), b=0.01) for i in range(K)]\n",
    "    )\n",
    "    \n",
    "    ## generate data\n",
    "    N = 1000\n",
    "    pmm = sample_PMM(bpmm)\n",
    "    X, S = sample_data(pmm, N)\n",
    "    \n",
    "    ## inference\n",
    "    max_iter = 100\n",
    "    results = {\n",
    "        \"VI\": learn_VI(X, bpmm),\n",
    "        \"GS\": learn_GS(X, bpmm),\n",
    "        \"CGS\": learn_CGS(X, bpmm),\n",
    "        S_est, post_bpmm, VB = \n",
    "    }\n",
    "\n",
    "    ## plot\n",
    "    visualize_1D(X, S, S_est)\n",
    "\n",
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
