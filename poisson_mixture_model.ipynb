{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as anim\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from typing import *\n",
    "\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各分布のハイパーパラメーターを保持するクラスを作る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gamma:\n",
    "    def __init__(self, *, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        \n",
    "    def get():\n",
    "        \"\"\" ガンマ分布をscipyのfrozen RV objectの形で返す。\n",
    "        Notes:\n",
    "            scipyのgamma distは、教科書の定義とちょっと異なる。教科書で言うハイパーパラメーターbは、\n",
    "            scaleという名前で指定する。\n",
    "            https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gamma.html\n",
    "        \"\"\"\n",
    "        return [stats.gamma(a=elem, scale=b) for elem in self.a]\n",
    "\n",
    "\n",
    "class Poisson:\n",
    "    def __init__(self, *, lambda_: List[float]):\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    def get():\n",
    "        \"\"\" ポアソン分布をscipyのfrozen RV objectの形で返す。\"\"\"\n",
    "        return [stats.poisson(mu=elem) for elem in self.lambda_]\n",
    "\n",
    "\n",
    "class BayesPoiMixModel:\n",
    "    def __init__(self, *, num_dim: int, num_cluster: int, alpha: List[float], gamDists: List[Gamma]):\n",
    "        \"\"\" ポアソン混合モデルの事前・事後分布を表現するクラスを構築する。\n",
    "        Args:\n",
    "            D: 観測データの次元\n",
    "            K: クラスター数\n",
    "            alpha : カテゴリ分布のパラメーター $\\pi$ の共役事前分布であるディリクレ分布のハイパーパラメーター (p.119)\n",
    "            gamLists: ポアソン分布のパラメーター $\\lambda$ の共役事前分布であるガンマ分布のハイパーパラメーター (p.129)\n",
    "        \"\"\"\n",
    "        self.num_dim = num_dim\n",
    "        self.num_cluster = num_cluster\n",
    "        self.alpha = np.ones(num_cluster) * alpha\n",
    "        self.gamma = [gamma]*num_cluster\n",
    "\n",
    "\n",
    "class PoiMixModel:\n",
    "    def __init__(self, *, num_dim: int, num_cluster: int, alpha: List[float], poiDists: List[Poisson]):\n",
    "        \"\"\" 真のポアソン混合モデルを構築する。\n",
    "        Args:\n",
    "            D: 観測データの次元\n",
    "            K: クラスター数\n",
    "            alpha : \n",
    "            poiDists: \n",
    "        \"\"\"\n",
    "        self.num_dim = num_dim\n",
    "        self.num_cluster = num_cluster\n",
    "        self.phi = alpha\n",
    "        self.poiDists = poiDists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ユーティリティ関数を定義する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ELBO(X, prior: BayesPoiMixModel, posterior: BayesPoiMixModel): # X: Mat{float}\n",
    "    \"\"\" ELBOを計算する。付録A.4を参照のこと。\n",
    "    Args:\n",
    "        X: \n",
    "        prior: \n",
    "        posterior: \n",
    "    \"\"\"\n",
    "    ln_expt_S = update_S(pos, X)\n",
    "    expt_S = np.exp(ln_expt_S)\n",
    "    K, N = expt_S.shape\n",
    "    D = X.shape[0]\n",
    "\n",
    "    expt_ln_lambda = np.zeros(S.shape) #np.matrix(np.zeros(D, K))\n",
    "    expt_lambda = np.zeros(S.shape) #np.matrix(np.zeros(D, K))\n",
    "    expt_ln_lkh = 0\n",
    "    for k in range(K):\n",
    "        expt_ln_lambda[:,k] = np.digamma(pos.cmp[k].a) - np.log(pos.cmp[k].b)\n",
    "        expt_lambda[:,k] = pos.cmp[k].a / pos.cmp[k].b\n",
    "        for n in range(N)\n",
    "            expt_ln_lkh += expt_S[k,n] * (\n",
    "                X[:, n].T * expt_ln_lambda[:,k] \n",
    "                    - sum(expt_lambda[:,k]) - sum(np.lgamma(X[:,n]+1))\n",
    "            )[1]\n",
    "\n",
    "    expt_ln_pS = sum(expt_S.T * (np.digamma(pos.alpha) - np.digamma(sum(pos.alpha))))\n",
    "    expt_ln_qS = sum(expt_S .* ln_expt_S)\n",
    "    KL_lambda = 0\n",
    "    for k in range(K):\n",
    "        KL_lambda += (\n",
    "            sum(pos.cmp[k].a)*np.log(pos.cmp[k].b) - sum(pri.cmp[k].a)*np.log(pri.cmp[k].b)\n",
    "                - sum(np.lgamma(pos.cmp[k].a)) + sum(np.lgamma(pri.cmp[k].a))\n",
    "                + (pos.cmp[k].a - pri.cmp[k].a).T * expt_ln_lambda[:,k]\n",
    "                + (pri.cmp[k].b - pos.cmp[k].b) * sum(expt_lambda[:,k])\n",
    "        )[1]\n",
    "    \n",
    "    KL_pi = (\n",
    "        np.lgamma(sum(pos.alpha)) - np.lgamma(sum(pri.alpha))\n",
    "             - sum(np.lgamma(pos.alpha)) + sum(np.lgamma(pri.alpha))\n",
    "             + (pos.alpha - pri.alpha).T * (np.digamma(pos.alpha) - np.digamma(sum(pos.alpha)))\n",
    "    )[1]\n",
    "    return expt_ln_lkh + expt_ln_pS - expt_ln_qS - (KL_lambda + KL_pi)\n",
    "\n",
    "\n",
    "def add_stats(bpmm: BayesPoiMixModel, X, S):  # X: Matrix{Float64}, S: Matrix{Float64}\n",
    "    D = bpmm.D\n",
    "    K = bpmm.K\n",
    "    sum_S = sum(S, 2)\n",
    "    alpha = [bpmm.alpha[k] + sum_S[k] for k in range(K)]\n",
    "    gamDists = [] # Vector{Gam}()\n",
    "    XS = X*(S.T);\n",
    "    for k in range(K):\n",
    "        a = [float(bpmm.cmp[k].a[d] + XS[d,k]) for d range(D)]\n",
    "        b = bpmm.cmp[k].b + sum_S[k]\n",
    "        gamDists.append(Gamma(a=a, b=b))\n",
    "    return BayesPoiMixModel(D=D, K=K, alpha=alpha, gamDists)\n",
    "\n",
    "\n",
    "def remove_stats(bpmm: BayesPoiMixModel, X, S): # X: Matrix{Float64}, S: Matrix{Float64}\n",
    "    return add_stats(bpmm, X, -S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a PMM given hyperparameters.\n",
    "def sample_PMM(bpmm: BayesPoiMixModel) -> PoiMixModel:\n",
    "    pois: List[Poisson] = [] \n",
    "    for c in bpmm.gamma_dists:\n",
    "        lambda_: List[float] = []\n",
    "        for d in range(bpmm.D):\n",
    "            lambda_.append(rand(Gamma(c.a[d], 1.0/c.b)))\n",
    "        pois.append(Poisson(lambda_ = lambda_)) \n",
    "    return PoiMixModel(\n",
    "        D = bpmm.D \n",
    "        , K = bpmm.K \n",
    "        , phi = rand(Dirichlet(bpmm.alpha))\n",
    "        , pois\n",
    "    )\n",
    "\n",
    "# Sample data from a specific PMM model.\n",
    "def sample_data(pmm: PoiMixModel, N: int):\n",
    "    X = np.zeros(pmm.D, N) #np.matrix(np.zeros(pmm.D, N))\n",
    "    S = categorical_sample(pmm.phi, N)\n",
    "    for n in range(N):\n",
    "        k = np.argmax(S[:, n])\n",
    "        for d in range(1, pmm.D)\n",
    "            X[d,n] = rand(Poisson(pmm.cmp[k].lambda_[d]))\n",
    "    return X, S\n",
    "\n",
    "#categorical_sample(p::Vector{Float64}) = categorical_sample(p, 1)[:,1]\n",
    "\n",
    "def categorical_sample(p: List[float], N: int = 1):\n",
    "    K = length(p)\n",
    "    S = np.zeros(K, N) # np.matrix(np.zeros(K, N))\n",
    "    S_tmp = rand(Categorical(p), N)\n",
    "    for k in range(K):\n",
    "        S[k,find(S_tmp.==k)] = 1\n",
    "    return S if N != 1 else S[:, 1]\n",
    "\n",
    "\n",
    "def init_S(X, bpmm: BayesPoiMixModel): # X: Matrix{float}\n",
    "    N = X.shape()[1]\n",
    "    S = categorical_sample(np.ones(K)/bpmm.cluster, N)    \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for Gibbs Sampling\n",
    "def sample_S_GS(pmm: PoiMixModel, X):  # X: Matrix{Float64}\n",
    "    D, N = X.shape\n",
    "    K = pmm.K\n",
    "    S = zeros(K, N)\n",
    "\n",
    "    tmp = [-sum(pmm.cmp[k].lambda) + log.(pmm.phi[k]) for k in range(K)]\n",
    "    ln_lambda_X = [X.T*np.log(pmm.cmp[k].lambda) for k in range(K)]\n",
    "    for n in 1 : N\n",
    "        tmp_ln_phi = [(tmp[k] + ln_lambda_X[k][n])::Float64 for k in range(K)]\n",
    "        tmp_ln_phi = tmp_ln_phi - logsumexp(tmp_ln_phi)\n",
    "        S[:,n] = categorical_sample(exp.(tmp_ln_phi))\n",
    "    return S\n",
    "\n",
    "\n",
    "def conduct_Gibbs_sampling(x, s, prior: BayesPoiMixModel, max_iter: int):  # X::Matrix{Float64}\n",
    "    # sample parameters\n",
    "    pmm = sample_PMM(bpmm)\n",
    "    # sample latent variables\n",
    "    S = sample_S_GS(pmm, X)\n",
    "    # update current model\n",
    "    bpmm = add_stats(prior, X, S)\n",
    "    return S, bpmm, calc_ELBO(X, prior, bpmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute posterior distribution via variational inference.\n",
    "def update_S(x, prior: BayesPoiMixModel):\n",
    "    D, N = size(X)\n",
    "    num_cluster = prior.num_cluster\n",
    "    ln_expt_S = zeros(K, N)\n",
    "    tmp = zeros(K)\n",
    "\n",
    "    sum_digamma_tmp = np.digamma(sum(bpmm.alpha))\n",
    "    for k range(num_cluster):\n",
    "        tmp[k] = - sum(bpmm.cmp[k].a) / bpmm.cmp[k].b\n",
    "        tmp[k] += digamma.(bpmm.alpha[k]) - sum_digamma_tmp\n",
    "    ln_lambda_X = [X.T*(np.digamma(bpmm.cmp[k].a) - np.log(bpmm.cmp[k].b)) for k in range(num_cluster)]\n",
    "    for n in range(N)\n",
    "        tmp_ln_pi =  [tmp[k] + ln_lambda_X[k][n] for k in 1 : K]\n",
    "        ln_expt_S[:,n] = tmp_ln_pi - logsumexp(tmp_ln_pi)\n",
    "    return ln_expt_S\n",
    "\n",
    "\n",
    "def conduct_variational_inference(x, s, prior_bpmm: BayesPoiMixModel, max_iter: int):  # X: Matrix{Float64}\n",
    "    \"\"\" 変分推論により事後分布を推定する。\n",
    "    \"\"\"\n",
    "    # E-step\n",
    "    expt_S = np.exp(update_S(bpmm, x))\n",
    "    # M-step\n",
    "    posterior = add_stats(prior, x, expt_S)\n",
    "    return expt_S, bpmm, calc_ELBO(x, prior, posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for Collapsed Gibbs Sampling\n",
    "def calc_ln_NB(Xn, gam: Gamma): # Xn: Vector{Float64}\n",
    "    return sum([\n",
    "        float(gam.a[d]*np.log(gam.b)\n",
    "            - np.lgamma(gam.a[d])\n",
    "            + np.lgamma(Xn[d] + gam.a[d])\n",
    "            - (Xn[d] + gam.a[d])*np.log(gam.b + 1)\n",
    "        ) for d in range(Xn.shape[0])\n",
    "    ])\n",
    "\n",
    "\n",
    "def sample_Sn(Xn, bpmm: BayesPoiMixModel): # Xn: Vector{Float64}\n",
    "    ln_tmp = [(calc_ln_NB(Xn, bpmm.cmp[k]) + np.log(bpmm.alpha[k])) for k in range(bpmm.K)]\n",
    "    ln_tmp = ln_tmp -  logsumexp(ln_tmp)\n",
    "    Sn = categorical_sample(np.exp(ln_tmp))\n",
    "    return Sn\n",
    "\n",
    "\n",
    "def sample_S_CGS(S, M, bpmm: BayesPoiMixModel):  # S: Matrix{Float64}, X: Matrix{Float64}\n",
    "    D, N = X.shape\n",
    "    K = S.shape[0]\n",
    "    for n in randperm(N)\n",
    "        bpmm = remove_stats(bpmm, X[:,[n]], S[:,[n]])  # remove\n",
    "        S[:,n] = sample_Sn(X[:,n], bpmm)  # sample\n",
    "        bpmm = add_stats(bpmm, X[:,[n]], S[:,[n]])  # insert\n",
    "    return S, bpmm\n",
    "\n",
    "def conduct_collapsed_Gibbs_sampling(x, s, prior: BayesPoiMixModel, max_iter: int):  \n",
    "    # directly sample S\n",
    "    s, posterior = sample_S_CGS(s, x, prior)\n",
    "    return s, bpmm, calc_ELBO(x, prior, posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_map = {\n",
    "    \"GS\": conduct_Gibbs_sampling, \n",
    "    \"VI\": conduct_variational_inference, \n",
    "    \"CGS\": conduct_collapsed_Gibbs_sampling,\n",
    "}\n",
    "\n",
    "def learn_step_by_step(x, s, prior: BayesPoiMixModel, algo: str):\n",
    "    \"\"\" 各アルゴリズムを用いて学習を実行する。\n",
    "    \n",
    "    Notes:\n",
    "    * 教科書に書かれている初期化の手続きは、括り出してここで処理している。\n",
    "    * アニメーションしようと思ってgeneratorを使ったら関数が複雑になってしまった（が、本質的コードはわずか）\n",
    "    \"\"\"\n",
    "    yield algorithm_map[algo](x, s, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Run():\n",
    "    def _main(*, num_dim, num_cluster, alpha, num_sample, out=None, max_iter=1000):\n",
    "        # モデルの構築\n",
    "        prior = BayesPoiMixModel(\n",
    "            num_dim=num_dim, \n",
    "            num_cluster=num_cluster, \n",
    "            alpha=alpha, \n",
    "            gammaLists=Gamma(a=1.0*np.ones(num_dim), b=0.01)\n",
    "        )\n",
    "\n",
    "        pmm = sample_PMM(prior)  # 真のモデルを作る\n",
    "        x, s = sample_data(pmm, N)  # データを作る\n",
    "        # 初期化する\n",
    "        s = init_S(x, prior)\n",
    "        prior = add_stats(prior, x, s)\n",
    "        # 1-stepごとにパラメーターを推定して描画\n",
    "\n",
    "        return {learn(x, prior, algo, max_iter) for algo in [\"GS\", \"VI\", \"CGS\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "図示に用いる関数を定義する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hist(ax, X, S, label):\n",
    "    counts, bins, patches = ax.hist(X.T, 20)\n",
    "    for i in range(len(patches)):\n",
    "        if counts[i] > 0:\n",
    "            S_tmp = S[:,bins[i] .<= X[1,:] .<= bins[i+1]]\n",
    "            S_sum = sum(S_tmp, 2) / sum(S_tmp)\n",
    "            patches[i].set_facecolor((S_sum[1], 0, S_sum[2]))\n",
    "    ax.set_title(label)\n",
    "\n",
    "\n",
    "def animate(x, S, S_est, out=None):\n",
    "    # separated figures\n",
    "    fig = plt.figure(figsize=(12, 7))\n",
    "    ax1 = fig.add_subplots(1, 1, 1)\n",
    "    ax2 = fig.add_subplots(1, 1, 2)\n",
    "    ax1.hist(x.T, 20)\n",
    "    ax1.set_title(\"observation\")\n",
    "    draw_hist(ax2, x, S_est, \"estimation\")\n",
    "    fig.tight_layout()\n",
    "    if out is not None:\n",
    "        fig.savefig(out)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 18))\n",
    "ani = anim.FuncAnimation(fig, animate, gen, blit=False, interval=INTERVAL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
