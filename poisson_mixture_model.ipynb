{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as anim\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import scipy.stats as stats\n",
    "from scipy.special import logsumexp, digamma\n",
    "import seaborn as sns\n",
    "from typing import *\n",
    "\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各分布のハイパーパラメーターなどを保持するクラスを作る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gamma:\n",
    "    def __init__(self, *, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        \n",
    "    def get():\n",
    "        \"\"\" ガンマ分布をscipyのfrozen RV objectの形で返す。\n",
    "        Notes:\n",
    "            scipyのgamma distは、教科書の定義とちょっと異なる。教科書で言うハイパーパラメーターbは、\n",
    "            scaleという名前で指定する。\n",
    "            https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gamma.html\n",
    "        \"\"\"\n",
    "        return [stats.gamma(a=elem, scale=b) for elem in self.a]\n",
    "\n",
    "\n",
    "class Poisson:\n",
    "    def __init__(self, *, lambda_: List[float]):\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    def get():\n",
    "        \"\"\" ポアソン分布をscipyのfrozen RV objectの形で返す。\"\"\"\n",
    "        return [stats.poisson(mu=elem) for elem in self.lambda_]\n",
    "\n",
    "\n",
    "class BayesPoiMixModel:\n",
    "    def __init__(self, *, num_dim: int, num_cluster: int, alpha, gamma):\n",
    "        \"\"\" ポアソン混合モデルの事前・事後分布を表現するクラスを構築する。\n",
    "        Args:\n",
    "            D: 観測データの次元\n",
    "            K: クラスター数\n",
    "            alpha : カテゴリ分布のパラメーター $\\pi$ の共役事前分布であるディリクレ分布のハイパーパラメーター (p.119)\n",
    "            gamma : ポアソン分布のパラメーター $\\lambda$ の共役事前分布であるガンマ分布のハイパーパラメーター (p.129)\n",
    "                * 非リストを指定した場合、全クラスターに同じ値を指定する。\n",
    "                * リストを指定した場合、各クラスターにおのおの指定された値を指定する。\n",
    "        Notes:\n",
    "            len(gamma) != num_clusterの場合は例外を投げる。\n",
    "        \"\"\"\n",
    "        self.num_dim = num_dim\n",
    "        self.num_cluster = num_cluster\n",
    "        self.alpha = np.ones(num_cluster) * alpha\n",
    "        if isinstance(gamma, list):\n",
    "            if len(gamma) != num_cluster:\n",
    "                raise \"in BayesPoiMixModel.__init__() : len(gamma) != num_cluster\"\n",
    "            self.gamma = gamma\n",
    "        else: \n",
    "            self.gamma = [gamma]*num_cluster\n",
    "\n",
    "\n",
    "class PoiMixModel:\n",
    "    def __init__(self, *, num_dim: int, num_cluster: int, phi, poisson: Poisson):\n",
    "        \"\"\" 真のポアソン混合モデルを構築する。\n",
    "        Args:\n",
    "            D: 観測データの次元\n",
    "            K: クラスター数\n",
    "            alpha : \n",
    "            poiDists: \n",
    "        \"\"\"\n",
    "        self.num_dim = num_dim\n",
    "        self.num_cluster = num_cluster\n",
    "        self.phi = phi\n",
    "        if isinstance(poisson, list):\n",
    "            if len(poisson) != num_cluster:\n",
    "                raise \"in PoiMixModel.__init__() : len(poisson) != num_cluster\"\n",
    "            self.poisson = poisson\n",
    "        else: \n",
    "            self.poisson = [poisson]*num_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ユーティリティ関数を定義する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ELBO(X, prior: BayesPoiMixModel, posterior: BayesPoiMixModel): # X: Mat{float}\n",
    "    \"\"\" ELBOを計算する。付録A.4を参照のこと。\n",
    "    Args:\n",
    "        X: \n",
    "        prior: \n",
    "        posterior: \n",
    "    \"\"\"\n",
    "    ln_expt_S = update_S(posterior, X)\n",
    "    expt_S = np.exp(ln_expt_S)\n",
    "    K, N = expt_S.shape\n",
    "    D = X.shape[0]\n",
    "\n",
    "    expt_ln_lambda = np.zeros(S.shape) #np.matrix(np.zeros(D, K))\n",
    "    expt_lambda = np.zeros(S.shape) #np.matrix(np.zeros(D, K))\n",
    "    expt_ln_lkh = 0\n",
    "    for k in range(K):\n",
    "        expt_ln_lambda[:,k] = digamma(posterior.gamma[k].a) - np.log(posterior.gamma[k].b)\n",
    "        expt_lambda[:,k] = posterior.gamma[k].a / pos.gamma[k].b\n",
    "        for n in range(N):\n",
    "            expt_ln_lkh += expt_S[k,n] * (\n",
    "                X[:, n].T * expt_ln_lambda[:,k] \n",
    "                    - sum(expt_lambda[:,k]) - sum(np.lgamma(X[:,n]+1))\n",
    "            )[1]\n",
    "\n",
    "    expt_ln_pS = sum(expt_S.T * (digamma(posterior.alpha) - digamma(sum(posterior.alpha))))\n",
    "    expt_ln_qS = sum(expt_S * ln_expt_S)\n",
    "    KL_lambda = 0\n",
    "    for k in range(K):\n",
    "        KL_lambda += (\n",
    "            sum(posterior.gamma[k].a)*np.log(posterior.gamma[k].b) \n",
    "                - sum(prior.gamma[k].a)*np.log(prior.gamma[k].b)\n",
    "                - sum(np.lgamma(posterior.gamma[k].a)) + sum(np.lgamma(prior.gamma[k].a))\n",
    "                + (posterior.gamma[k].a - prior.gamma[k].a).T * expt_ln_lambda[:,k]\n",
    "                + (prior.gamma[k].b - posterior.gamma[k].b) * sum(expt_lambda[:,k])\n",
    "        )[1]\n",
    "    \n",
    "    KL_pi = (\n",
    "        np.lgamma(sum(posterior.alpha)) \n",
    "            - np.lgamma(sum(prior.alpha))\n",
    "            - sum(np.lgamma(posterior.alpha)) + sum(np.lgamma(prior.alpha))\n",
    "            + (posterior.alpha - prior.alpha).T \n",
    "        * (digamma(posterior.alpha) - digamma(sum(posterior.alpha)))\n",
    "    )[1]\n",
    "    return expt_ln_lkh + expt_ln_pS - expt_ln_qS - (KL_lambda + KL_pi)\n",
    "\n",
    "\n",
    "def add_stats(bpmm: BayesPoiMixModel, X, S):  # X: Matrix{Float64}, S: Matrix{Float64}\n",
    "    D = bpmm.num_dim\n",
    "    K = bpmm.num_cluster\n",
    "    sum_S = sum(S, 2)\n",
    "    alpha = [bpmm.alpha[k] + sum_S[k] for k in range(K)]\n",
    "    gamDists = [] # Vector{Gam}()\n",
    "    XS = X @ S.T;\n",
    "    for k in range(K):\n",
    "        a = [float(bpmm.gamma[k].a[d] + XS[d,k]) for d in range(D)]\n",
    "        b = bpmm.gamma[k].b + sum_S[k]\n",
    "        gamDists.append(Gamma(a=a, b=b))\n",
    "    return BayesPoiMixModel(num_dim=D, num_cluster=K, alpha=alpha, gamma=gamDists)\n",
    "\n",
    "\n",
    "def remove_stats(bpmm: BayesPoiMixModel, X, S): # X: Matrix{Float64}, S: Matrix{Float64}\n",
    "    return add_stats(bpmm, X, -S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a PMM given hyperparameters.\n",
    "def sample_PMM(bpmm: BayesPoiMixModel) -> PoiMixModel:\n",
    "    pois = []\n",
    "    for c in bpmm.gamma:\n",
    "        lambda_ = np.zeros(bpmm.num_dim)\n",
    "        for d in range(bpmm.num_dim):\n",
    "            lambda_[d] = rnd.gamma(shape=c.a[d], scale=1.0/c.b)\n",
    "        pois.append(Poisson(lambda_ = lambda_))\n",
    "    return PoiMixModel(\n",
    "        num_dim = bpmm.num_dim, \n",
    "        num_cluster = bpmm.num_cluster,\n",
    "        phi = rnd.dirichlet(bpmm.alpha),\n",
    "        poisson=pois\n",
    "    )\n",
    "\n",
    "\n",
    "# Sample data from a specific PMM model.\n",
    "def sample_data(pmm: PoiMixModel, N: int):\n",
    "    x = np.zeros((pmm.num_dim, N)) #np.matrix(np.zeros(pmm.D, N))\n",
    "    s = categorical_sample(pmm.phi, N)\n",
    "    for n in range(N):\n",
    "        k = np.argmax(s[:, n])\n",
    "        for d in range(pmm.num_dim):\n",
    "            x[d, n] = rnd.poisson(pmm.poisson[k].lambda_[d])\n",
    "    return x, s\n",
    "\n",
    "#categorical_sample(p::Vector{Float64}) = categorical_sample(p, 1)[:,1]\n",
    "\n",
    "def categorical_sample(p: List[float], N: int = 1):\n",
    "    K = len(p)\n",
    "    S = np.zeros((K, N)) # np.matrix(np.zeros(K, N))\n",
    "    # numpy.randomにはわかりやすくcategorical sampleを行う関数がない。\n",
    "    # ググったところ、numpy.random.Generator.choice()がカテゴリ分布になっているらしい。\n",
    "    # http://bois.caltech.edu/distribution_explorer/discrete/categorical.html\n",
    "    S_tmp = rnd.default_rng().choice(len(p), N, p=p)\n",
    "    for k in range(K):\n",
    "        #S[S[k, S_tmp == k]] = 1\n",
    "        #S[k,find(S_tmp==k)] = 1\n",
    "        S[k, S_tmp == k] = 1\n",
    "    return S if N != 1 else S[:, 0]\n",
    "\n",
    "\n",
    "def init_S(x, bpmm: BayesPoiMixModel): # X: Matrix{float}\n",
    "    s = categorical_sample(np.ones(bpmm.num_cluster)/bpmm.num_cluster, x.shape[1])    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ギブスサンプリングを実装する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for Gibbs Sampling\n",
    "def sample_S_GS(pmm: PoiMixModel, X):  # X: Matrix{Float64}\n",
    "    D, N = X.shape\n",
    "    K = pmm.num_cluster\n",
    "    S = np.zeros((K, N))\n",
    "    tmp = [-sum(pmm.poisson[k].lambda_) + np.log(pmm.phi[k]) for k in range(K)]\n",
    "    ln_lambda_X = [X.T*np.log(pmm.poisson[k].lambda_) for k in range(K)]\n",
    "    for n in range(N):\n",
    "        tmp_ln_phi = [(tmp[k] + ln_lambda_X[k][n]) for k in range(K)]\n",
    "        # 知らなかったのでメモ：詳細は https://qiita.com/BigSea/items/1949b3ceefcec4fc32ea\n",
    "        # logsumexp()ってなんだよlog(sum(exp(.)))でええやん、、、？みたいな気持ちになるが、\n",
    "        # log(sum(exp(.)))した結果はアンダー・オーバーフローしない範囲に収まっていても、\n",
    "        # exp(.)の時点でアンダー・オーバーフローしたら全てがおじゃんなので、これを回避するための計算法\n",
    "        # （面白い；実際書き下して回したらアンダーフローした、そりゃそうだ）\n",
    "        tmp_ln_phi = tmp_ln_phi - logsumexp(tmp_ln_phi)\n",
    "        S[:,n] = categorical_sample(np.exp(tmp_ln_phi).T[0,:])\n",
    "    return S\n",
    "\n",
    "\n",
    "def conduct_Gibbs_sampling(x, s, prior: BayesPoiMixModel):  # X::Matrix{Float64}\n",
    "    # sample parameters\n",
    "    pmm = sample_PMM(prior)\n",
    "    # sample latent variables\n",
    "    s = sample_S_GS(pmm, x)\n",
    "    # update current model\n",
    "    bpmm = add_stats(prior, x, s)\n",
    "    return s, bpmm, calc_ELBO(x, prior, bpmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変分推論を実装する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute posterior distribution via variational inference.\n",
    "def update_S(prior: BayesPoiMixModel, x):\n",
    "    D, N = x.shape\n",
    "    num_cluster = prior.num_cluster\n",
    "    ln_expt_S = np.zeros((num_cluster, N))\n",
    "    tmp = np.zeros(num_cluster)\n",
    "\n",
    "    sum_digamma_tmp = digamma(sum(bpmm.alpha))\n",
    "    for k in range(num_cluster):\n",
    "        tmp[k] = - sum(bpmm.cmp[k].a) / bpmm.cmp[k].b\n",
    "        tmp[k] += digamma(bpmm.alpha[k]) - sum_digamma_tmp\n",
    "    ln_lambda_X = [x.T*(digamma(bpmm.cmp[k].a) - np.log(bpmm.cmp[k].b)) for k in range(num_cluster)]\n",
    "    for n in range(N):\n",
    "        tmp_ln_pi =  [tmp[k] + ln_lambda_X[k][n] for k in range(K)]\n",
    "        ln_expt_S[:,n] = tmp_ln_pi - logsumexp(tmp_ln_pi)\n",
    "    return ln_expt_S\n",
    "\n",
    "\n",
    "def conduct_variational_inference(x, s, prior_bpmm: BayesPoiMixModel):  # X: Matrix{Float64}\n",
    "    \"\"\" 変分推論により事後分布を推定する。\n",
    "    \"\"\"\n",
    "    # E-step\n",
    "    expt_S = np.exp(update_S(bpmm, x))\n",
    "    # M-step\n",
    "    posterior = add_stats(prior, x, expt_S)\n",
    "    return expt_S, bpmm, calc_ELBO(x, prior, posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "崩壊型ギブスサンプリングを実装する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for Collapsed Gibbs Sampling\n",
    "def calc_ln_NB(Xn, gam: Gamma): # Xn: Vector{Float64}\n",
    "    return sum([\n",
    "        float(gam.a[d]*np.log(gam.b)\n",
    "            - np.lgamma(gam.a[d])\n",
    "            + np.lgamma(Xn[d] + gam.a[d])\n",
    "            - (Xn[d] + gam.a[d])*np.log(gam.b + 1)\n",
    "        ) for d in range(Xn.shape[0])\n",
    "    ])\n",
    "\n",
    "\n",
    "def sample_Sn(Xn, bpmm: BayesPoiMixModel): # Xn: Vector{Float64}\n",
    "    ln_tmp = [(calc_ln_NB(Xn, bpmm.cmp[k]) + np.log(bpmm.alpha[k])) for k in range(bpmm.K)]\n",
    "    ln_tmp = ln_tmp -  logsumexp(ln_tmp)\n",
    "    Sn = categorical_sample(np.exp(ln_tmp))\n",
    "    return Sn\n",
    "\n",
    "\n",
    "def sample_S_CGS(S, M, bpmm: BayesPoiMixModel):  # S: Matrix{Float64}, X: Matrix{Float64}\n",
    "    D, N = X.shape\n",
    "    K = S.shape[0]\n",
    "    for n in randperm(N):\n",
    "        bpmm = remove_stats(bpmm, X[:,[n]], S[:,[n]])  # remove\n",
    "        S[:,n] = sample_Sn(X[:,n], bpmm)  # sample\n",
    "        bpmm = add_stats(bpmm, X[:,[n]], S[:,[n]])  # insert\n",
    "    return S, bpmm\n",
    "\n",
    "\n",
    "def conduct_collapsed_Gibbs_sampling(x, s, prior: BayesPoiMixModel):  \n",
    "    # directly sample S\n",
    "    s, posterior = sample_S_CGS(s, x, prior)\n",
    "    return s, bpmm, calc_ELBO(x, prior, posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指定されたアルゴリズムをstep-by-stepに実行していくwrapperを作っておく。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = {\n",
    "    \"GS\": conduct_Gibbs_sampling, \n",
    "    \"VI\": conduct_variational_inference, \n",
    "    \"CGS\": conduct_collapsed_Gibbs_sampling,\n",
    "}\n",
    "\n",
    "\n",
    "def learn_step_by_step(x, s, prior: BayesPoiMixModel, algo: str):\n",
    "    return algorithms[algo](x, s, prior)\n",
    "\n",
    "\n",
    "class Cache:\n",
    "    def __init__(self, x, s, prior):\n",
    "        self.x = x\n",
    "        self.s = s\n",
    "        self.prior = prior\n",
    "\n",
    "\n",
    "def learn(x, s, prior: BayesPoiMixModel, iter_=1000):\n",
    "    # 初期化\n",
    "    s = init_S(x, prior)\n",
    "    prior = add_stats(prior, x, s)\n",
    "    \n",
    "    # 各アルゴリズムの結果をキャッシュしておく変数を作る\n",
    "    gs, vi, cgs = Cache(x, s, prior), Cache(x, s, prior), Cache(x, s, prior)\n",
    "    for i in range(iter_):\n",
    "        gs = learn_step_by_step(gs.x, gs.s, gs.prior, \"GS\")\n",
    "        vi = learn_step_by_step(vi.x, vi.s, vi.prior, \"VI\")\n",
    "        cgs = learn_step_by_step(cgs.x, cgs.s, cgs.prior, \"CGS\")\n",
    "    \n",
    "    return gs, vi, cgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルを作って、クラスタリングを行うデータを見てみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([182., 182.,  51.,  36., 100., 191., 145.,  76.,  25.,  12.]),\n",
       " array([ 0. ,  3.2,  6.4,  9.6, 12.8, 16. , 19.2, 22.4, 25.6, 28.8, 32. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# モデルの構築\n",
    "prior_ = BayesPoiMixModel(\n",
    "    num_dim=1, \n",
    "    num_cluster=2, \n",
    "    alpha=100.0, \n",
    "    gamma=Gamma(a=1.0*np.ones(1), b=0.01)\n",
    ")\n",
    "\n",
    "pmm_ = sample_PMM(prior_)  # 真のモデルを作る\n",
    "x_, s_ = sample_data(pmm_, 1000)  # データを作る\n",
    "plt.hist(x_[0, :], alpha=.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ざっくりと2峰性の分布になっていることがわかる。このデータに対してクラスタリングを行ってみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bpmm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-54a41deb7847>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-c7532e43b817>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(x, s, prior, iter_)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn_step_by_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"GS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mvi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn_step_by_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"VI\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mcgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn_step_by_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CGS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-c7532e43b817>\u001b[0m in \u001b[0;36mlearn_step_by_step\u001b[0;34m(x, s, prior, algo)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlearn_step_by_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBayesPoiMixModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-3ce8f2f21c34>\u001b[0m in \u001b[0;36mconduct_Gibbs_sampling\u001b[0;34m(x, s, prior)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# update current model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mbpmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc_ELBO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpmm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-9182f249d54d>\u001b[0m in \u001b[0;36mcalc_ELBO\u001b[0;34m(X, prior, posterior)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mposterior\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \"\"\"\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mln_expt_S\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_S\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mexpt_S\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mln_expt_S\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpt_S\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-fa1a52748c48>\u001b[0m in \u001b[0;36mupdate_S\u001b[0;34m(prior, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msum_digamma_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdigamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbpmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbpmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbpmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bpmm' is not defined"
     ]
    }
   ],
   "source": [
    "results = learn(x_, s_, prior_, iter_=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
