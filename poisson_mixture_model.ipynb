{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as anim\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from typing import *\n",
    "\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各分布のハイパーパラメーターなどを保持するクラスを作る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gamma:\n",
    "    def __init__(self, *, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        \n",
    "    def get():\n",
    "        \"\"\" ガンマ分布をscipyのfrozen RV objectの形で返す。\n",
    "        Notes:\n",
    "            scipyのgamma distは、教科書の定義とちょっと異なる。教科書で言うハイパーパラメーターbは、\n",
    "            scaleという名前で指定する。\n",
    "            https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gamma.html\n",
    "        \"\"\"\n",
    "        return [stats.gamma(a=elem, scale=b) for elem in self.a]\n",
    "\n",
    "\n",
    "class Poisson:\n",
    "    def __init__(self, *, lambda_: List[float]):\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    def get():\n",
    "        \"\"\" ポアソン分布をscipyのfrozen RV objectの形で返す。\"\"\"\n",
    "        return [stats.poisson(mu=elem) for elem in self.lambda_]\n",
    "\n",
    "\n",
    "class BayesPoiMixModel:\n",
    "    def __init__(self, *, num_dim: int, num_cluster: int, alpha, gamma):\n",
    "        \"\"\" ポアソン混合モデルの事前・事後分布を表現するクラスを構築する。\n",
    "        Args:\n",
    "            D: 観測データの次元\n",
    "            K: クラスター数\n",
    "            alpha : カテゴリ分布のパラメーター $\\pi$ の共役事前分布であるディリクレ分布のハイパーパラメーター (p.119)\n",
    "            gamma : ポアソン分布のパラメーター $\\lambda$ の共役事前分布であるガンマ分布のハイパーパラメーター (p.129)\n",
    "                * 非リストを指定した場合、全クラスターに同じ値を指定する。\n",
    "                * リストを指定した場合、各クラスターにおのおの指定された値を指定する。ただし、len(gamma) != num_clusterの場合は例外を投げる。\n",
    "        \"\"\"\n",
    "        self.num_dim = num_dim\n",
    "        self.num_cluster = num_cluster\n",
    "        self.alpha = np.ones(num_cluster) * alpha\n",
    "        if isinstance(gamma, list):\n",
    "            if len(gamma) != num_cluster:\n",
    "                raise \"in BayesPoiMixModel.__init__() : len(gamma) != num_cluster\"\n",
    "            self.gamma = gamma\n",
    "        else: \n",
    "            self.gamma = [gamma]*num_cluster\n",
    "\n",
    "\n",
    "class PoiMixModel:\n",
    "    def __init__(self, *, num_dim: int, num_cluster: int, phi, poisson: Poisson):\n",
    "        \"\"\" 真のポアソン混合モデルを構築する。\n",
    "        Args:\n",
    "            D: 観測データの次元\n",
    "            K: クラスター数\n",
    "            alpha : \n",
    "            poiDists: \n",
    "        \"\"\"\n",
    "        self.num_dim = num_dim\n",
    "        self.num_cluster = num_cluster\n",
    "        self.phi = phi\n",
    "        if isinstance(poisson, list):\n",
    "            if len(poisson) != num_cluster:\n",
    "                raise \"in PoiMixModel.__init__() : len(poisson) != num_cluster\"\n",
    "            self.poisson = poisson\n",
    "        else: \n",
    "            self.poisson = [poisson]*num_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ユーティリティ関数を定義する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ELBO(X, prior: BayesPoiMixModel, posterior: BayesPoiMixModel): # X: Mat{float}\n",
    "    \"\"\" ELBOを計算する。付録A.4を参照のこと。\n",
    "    Args:\n",
    "        X: \n",
    "        prior: \n",
    "        posterior: \n",
    "    \"\"\"\n",
    "    ln_expt_S = update_S(pos, X)\n",
    "    expt_S = np.exp(ln_expt_S)\n",
    "    K, N = expt_S.shape\n",
    "    D = X.shape[0]\n",
    "\n",
    "    expt_ln_lambda = np.zeros(S.shape) #np.matrix(np.zeros(D, K))\n",
    "    expt_lambda = np.zeros(S.shape) #np.matrix(np.zeros(D, K))\n",
    "    expt_ln_lkh = 0\n",
    "    for k in range(K):\n",
    "        expt_ln_lambda[:,k] = np.digamma(pos.cmp[k].a) - np.log(pos.cmp[k].b)\n",
    "        expt_lambda[:,k] = pos.cmp[k].a / pos.cmp[k].b\n",
    "        for n in range(N)\n",
    "            expt_ln_lkh += expt_S[k,n] * (\n",
    "                X[:, n].T * expt_ln_lambda[:,k] \n",
    "                    - sum(expt_lambda[:,k]) - sum(np.lgamma(X[:,n]+1))\n",
    "            )[1]\n",
    "\n",
    "    expt_ln_pS = sum(expt_S.T * (np.digamma(pos.alpha) - np.digamma(sum(pos.alpha))))\n",
    "    expt_ln_qS = sum(expt_S .* ln_expt_S)\n",
    "    KL_lambda = 0\n",
    "    for k in range(K):\n",
    "        KL_lambda += (\n",
    "            sum(pos.cmp[k].a)*np.log(pos.cmp[k].b) - sum(pri.cmp[k].a)*np.log(pri.cmp[k].b)\n",
    "                - sum(np.lgamma(pos.cmp[k].a)) + sum(np.lgamma(pri.cmp[k].a))\n",
    "                + (pos.cmp[k].a - pri.cmp[k].a).T * expt_ln_lambda[:,k]\n",
    "                + (pri.cmp[k].b - pos.cmp[k].b) * sum(expt_lambda[:,k])\n",
    "        )[1]\n",
    "    \n",
    "    KL_pi = (\n",
    "        np.lgamma(sum(pos.alpha)) - np.lgamma(sum(pri.alpha))\n",
    "             - sum(np.lgamma(pos.alpha)) + sum(np.lgamma(pri.alpha))\n",
    "             + (pos.alpha - pri.alpha).T * (np.digamma(pos.alpha) - np.digamma(sum(pos.alpha)))\n",
    "    )[1]\n",
    "    return expt_ln_lkh + expt_ln_pS - expt_ln_qS - (KL_lambda + KL_pi)\n",
    "\n",
    "\n",
    "def add_stats(bpmm: BayesPoiMixModel, X, S):  # X: Matrix{Float64}, S: Matrix{Float64}\n",
    "    D = bpmm.D\n",
    "    K = bpmm.K\n",
    "    sum_S = sum(S, 2)\n",
    "    alpha = [bpmm.alpha[k] + sum_S[k] for k in range(K)]\n",
    "    gamDists = [] # Vector{Gam}()\n",
    "    XS = X*(S.T);\n",
    "    for k in range(K):\n",
    "        a = [float(bpmm.cmp[k].a[d] + XS[d,k]) for d range(D)]\n",
    "        b = bpmm.cmp[k].b + sum_S[k]\n",
    "        gamDists.append(Gamma(a=a, b=b))\n",
    "    return BayesPoiMixModel(D=D, K=K, alpha=alpha, gamDists)\n",
    "\n",
    "\n",
    "def remove_stats(bpmm: BayesPoiMixModel, X, S): # X: Matrix{Float64}, S: Matrix{Float64}\n",
    "    return add_stats(bpmm, X, -S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a PMM given hyperparameters.\n",
    "def sample_PMM(bpmm: BayesPoiMixModel) -> PoiMixModel:\n",
    "    pois: List[Poisson] = [] \n",
    "    for c in bpmm.gamma:\n",
    "        lambda_: List[float] = []\n",
    "        for d in range(bpmm.D):\n",
    "            lambda_.append(rand(Gamma(c.a[d], 1.0/c.b)))\n",
    "        pois.append(Poisson(lambda_ = lambda_)) \n",
    "    return PoiMixModel(\n",
    "        num_dim = bpmm.num_dim, \n",
    "        num_cluster = bpmm.num_cluster,\n",
    "        phi = rand(Dirichlet(bpmm.alpha)),\n",
    "        pois\n",
    "    )\n",
    "\n",
    "# Sample data from a specific PMM model.\n",
    "def sample_data(pmm: PoiMixModel, N: int):\n",
    "    X = np.zeros(pmm.D, N) #np.matrix(np.zeros(pmm.D, N))\n",
    "    S = categorical_sample(pmm.phi, N)\n",
    "    for n in range(N):\n",
    "        k = np.argmax(S[:, n])\n",
    "        for d in range(1, pmm.D)\n",
    "            X[d,n] = rand(Poisson(pmm.cmp[k].lambda_[d]))\n",
    "    return X, S\n",
    "\n",
    "#categorical_sample(p::Vector{Float64}) = categorical_sample(p, 1)[:,1]\n",
    "\n",
    "def categorical_sample(p: List[float], N: int = 1):\n",
    "    K = length(p)\n",
    "    S = np.zeros(K, N) # np.matrix(np.zeros(K, N))\n",
    "    S_tmp = rand(Categorical(p), N)\n",
    "    for k in range(K):\n",
    "        S[k,find(S_tmp.==k)] = 1\n",
    "    return S if N != 1 else S[:, 1]\n",
    "\n",
    "\n",
    "def init_S(X, bpmm: BayesPoiMixModel): # X: Matrix{float}\n",
    "    N = X.shape()[1]\n",
    "    S = categorical_sample(np.ones(K)/bpmm.cluster, N)    \n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ギブスサンプリングを実装する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for Gibbs Sampling\n",
    "def sample_S_GS(pmm: PoiMixModel, X):  # X: Matrix{Float64}\n",
    "    D, N = X.shape\n",
    "    K = pmm.K\n",
    "    S = zeros(K, N)\n",
    "\n",
    "    tmp = [-sum(pmm.cmp[k].lambda) + log.(pmm.phi[k]) for k in range(K)]\n",
    "    ln_lambda_X = [X.T*np.log(pmm.cmp[k].lambda) for k in range(K)]\n",
    "    for n in 1 : N\n",
    "        tmp_ln_phi = [(tmp[k] + ln_lambda_X[k][n])::Float64 for k in range(K)]\n",
    "        tmp_ln_phi = tmp_ln_phi - logsumexp(tmp_ln_phi)\n",
    "        S[:,n] = categorical_sample(exp.(tmp_ln_phi))\n",
    "    return S\n",
    "\n",
    "\n",
    "def conduct_Gibbs_sampling(x, s, prior: BayesPoiMixModel, max_iter: int):  # X::Matrix{Float64}\n",
    "    # sample parameters\n",
    "    pmm = sample_PMM(bpmm)\n",
    "    # sample latent variables\n",
    "    S = sample_S_GS(pmm, X)\n",
    "    # update current model\n",
    "    bpmm = add_stats(prior, X, S)\n",
    "    return S, bpmm, calc_ELBO(X, prior, bpmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変分推論を実装する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute posterior distribution via variational inference.\n",
    "def update_S(x, prior: BayesPoiMixModel):\n",
    "    D, N = size(X)\n",
    "    num_cluster = prior.num_cluster\n",
    "    ln_expt_S = zeros(K, N)\n",
    "    tmp = zeros(K)\n",
    "\n",
    "    sum_digamma_tmp = np.digamma(sum(bpmm.alpha))\n",
    "    for k range(num_cluster):\n",
    "        tmp[k] = - sum(bpmm.cmp[k].a) / bpmm.cmp[k].b\n",
    "        tmp[k] += digamma.(bpmm.alpha[k]) - sum_digamma_tmp\n",
    "    ln_lambda_X = [X.T*(np.digamma(bpmm.cmp[k].a) - np.log(bpmm.cmp[k].b)) for k in range(num_cluster)]\n",
    "    for n in range(N)\n",
    "        tmp_ln_pi =  [tmp[k] + ln_lambda_X[k][n] for k in 1 : K]\n",
    "        ln_expt_S[:,n] = tmp_ln_pi - logsumexp(tmp_ln_pi)\n",
    "    return ln_expt_S\n",
    "\n",
    "\n",
    "def conduct_variational_inference(x, s, prior_bpmm: BayesPoiMixModel, max_iter: int):  # X: Matrix{Float64}\n",
    "    \"\"\" 変分推論により事後分布を推定する。\n",
    "    \"\"\"\n",
    "    # E-step\n",
    "    expt_S = np.exp(update_S(bpmm, x))\n",
    "    # M-step\n",
    "    posterior = add_stats(prior, x, expt_S)\n",
    "    return expt_S, bpmm, calc_ELBO(x, prior, posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "崩壊型ギブスサンプリングを実装する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for Collapsed Gibbs Sampling\n",
    "def calc_ln_NB(Xn, gam: Gamma): # Xn: Vector{Float64}\n",
    "    return sum([\n",
    "        float(gam.a[d]*np.log(gam.b)\n",
    "            - np.lgamma(gam.a[d])\n",
    "            + np.lgamma(Xn[d] + gam.a[d])\n",
    "            - (Xn[d] + gam.a[d])*np.log(gam.b + 1)\n",
    "        ) for d in range(Xn.shape[0])\n",
    "    ])\n",
    "\n",
    "\n",
    "def sample_Sn(Xn, bpmm: BayesPoiMixModel): # Xn: Vector{Float64}\n",
    "    ln_tmp = [(calc_ln_NB(Xn, bpmm.cmp[k]) + np.log(bpmm.alpha[k])) for k in range(bpmm.K)]\n",
    "    ln_tmp = ln_tmp -  logsumexp(ln_tmp)\n",
    "    Sn = categorical_sample(np.exp(ln_tmp))\n",
    "    return Sn\n",
    "\n",
    "\n",
    "def sample_S_CGS(S, M, bpmm: BayesPoiMixModel):  # S: Matrix{Float64}, X: Matrix{Float64}\n",
    "    D, N = X.shape\n",
    "    K = S.shape[0]\n",
    "    for n in randperm(N)\n",
    "        bpmm = remove_stats(bpmm, X[:,[n]], S[:,[n]])  # remove\n",
    "        S[:,n] = sample_Sn(X[:,n], bpmm)  # sample\n",
    "        bpmm = add_stats(bpmm, X[:,[n]], S[:,[n]])  # insert\n",
    "    return S, bpmm\n",
    "\n",
    "def conduct_collapsed_Gibbs_sampling(x, s, prior: BayesPoiMixModel, max_iter: int):  \n",
    "    # directly sample S\n",
    "    s, posterior = sample_S_CGS(s, x, prior)\n",
    "    return s, bpmm, calc_ELBO(x, prior, posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指定されたアルゴリズムをstep-by-stepに実行していくwrapperを作っておく。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = {\n",
    "    \"GS\": conduct_Gibbs_sampling, \n",
    "    \"VI\": conduct_variational_inference, \n",
    "    \"CGS\": conduct_collapsed_Gibbs_sampling,\n",
    "}\n",
    "\n",
    "def learn_step_by_step(x, s, prior: BayesPoiMixModel, algo: str):\n",
    "    yield algorithms[algo](x, s, prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "アニメーションの各フレームでアルゴリズムを実行するクラスを作る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Run(anim.TimedAnimation):\n",
    "    ALGORITHMS = {\n",
    "        \"GS\": \"Gibbs sampling\", \n",
    "        \"VI\": \"Variational inference\",\n",
    "        \"CGS\": \"Collapsed Gibbs sampling\",\n",
    "    }\n",
    "    \n",
    "    def _init_vars(self, x, prior):\n",
    "        # 初期化する\n",
    "        self.s = init_S(x, prior)\n",
    "        self.prior = add_stats(prior, x, self.s)\n",
    "    \n",
    "    def _main(self, *, num_dim, num_cluster, alpha, num_sample, out=None, max_iter=1000):\n",
    "        # 1-stepごとにパラメーターを推定して描画\n",
    "        self.gs = learn_step_by_step(*(self.gs), \"GS\")\n",
    "        self.vi = learn_step_by_step(*(self.vi), \"VI\")\n",
    "        self.cgs = learn_step_by_step(*(self.cgs), \"CGS\")\n",
    "    \n",
    "    # ここから下は描画用関数で、本質的なものでは無い\n",
    "    def __init__(self, prior, x, max_iter):\n",
    "        \"\"\" オブジェクトを構築する。\n",
    "        \"\"\"\n",
    "        self.max_iter = max_iter\n",
    "        self._init_vars(prior, x)  # 初期化\n",
    "        \n",
    "        # 図の初期化\n",
    "        fig = plt.figure()\n",
    "        axs = tuple(fig.add_subplot(2, 2, i+1) for i in range(4))\n",
    "        for i, ax in enumerate(axs):\n",
    "            if i == 0:\n",
    "                # line object\n",
    "                ax.set_xlabel(\"iteration\")\n",
    "                ax.set_xlim([0, max_iter])\n",
    "            else:\n",
    "                ax.hist()\n",
    "                ax.set_title(ALGORITHMS[i-1])\n",
    "                ax.set_xlabel(\"X\")\n",
    "                ax.set_xlim([])\n",
    "        \n",
    "        # 基底クラスのコンストラクタを呼び出しておく\n",
    "        anim.TimedAnimation.__init__(self, fig, interval=50, blit=True)\n",
    "    \n",
    "    def _draw_hist(ax, X, S, label):\n",
    "        counts, bins, patches = ax.hist(X.T, 20)\n",
    "        for i in range(len(patches)):\n",
    "            if counts[i] > 0:\n",
    "                S_tmp = S[:,bins[i] .<= X[1,:] .<= bins[i+1]]\n",
    "                S_sum = sum(S_tmp, 2) / sum(S_tmp)\n",
    "                patches[i].set_facecolor((S_sum[1], 0, S_sum[2]))\n",
    "        ax.set_title(label)\n",
    "    \n",
    "    def _draw_frame(self, framedata):\n",
    "        i = framedata\n",
    "        head = i - 1\n",
    "        head_slice = (self.t > self.t[i] - 1.0) & (self.t < self.t[i])\n",
    "\n",
    "        self.line3.set_data(self.x[:i], self.z[:i])\n",
    "        self.line3a.set_data(self.x[head_slice], self.z[head_slice])\n",
    "        self.line3e.set_data(self.x[head], self.z[head])\n",
    "\n",
    "        self._drawn_artists = [self.line3, self.line3a, self.line3e]\n",
    "\n",
    "    def new_frame_seq(self):\n",
    "        return iter(range(self.max_iter))\n",
    "\n",
    "    def _init_draw(self):\n",
    "        lines = [self.line3, self.line3a, self.line3e]\n",
    "        for l in lines:\n",
    "            l.set_data([], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルを作って、クラスタリングを行うデータを見てみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの構築\n",
    "prior = BayesPoiMixModel(\n",
    "    num_dim=num_dim, \n",
    "    num_cluster=num_cluster, \n",
    "    alpha=alpha, \n",
    "    gammaLists=Gamma(a=1.0*np.ones(num_dim), b=0.01)\n",
    ")\n",
    "\n",
    "pmm = sample_PMM(prior)  # 真のモデルを作る\n",
    "x, s = sample_data(pmm, N)  # データを作る\n",
    "plt.hist(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クラスタリングを行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Run(prior, x, nax_iter=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
